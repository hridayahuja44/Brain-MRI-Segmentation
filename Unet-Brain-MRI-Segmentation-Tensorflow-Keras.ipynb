{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "import tensorflow as tf\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from glob import glob\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coeffs(y_true, y_pred, smooth=100):\n",
    "    y_true_flatten = K.flatten(y_true)\n",
    "    y_pred_flatten = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_flatten * y_pred_flatten)\n",
    "    union = K.sum(y_true_flatten) + K.sum(y_pred_flatten)\n",
    "    return (2 * intersection + smooth) / (union + smooth)\n",
    "def deep_learning_model(input_shape, num_hidden_units, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.Dense(num_hidden_units, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "def norm_diagnose(img, mask):\n",
    "    img = img / 255\n",
    "    mask = mask / 255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return(img, mask)\n",
    "def cnn_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "def intersection_over_union(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    sum = K.sum(y_true + y_pred)\n",
    "    intersection_over_union = (intersection + smooth) / (sum - intersection + smooth)\n",
    "    return intersection_over_union\n",
    "def dice_coeffloss(y_true, y_pred, smooth=100):\n",
    "    return -dice_coeffs(y_true, y_pred, smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename_train = []\n",
    "image_hght = 256\n",
    "image_wdth = 256\n",
    "mask_files = glob(pathname='kaggle_3m/*/*_mask*')\n",
    "for i in mask_files:\n",
    "    image_filename_train.append(i.replace('_mask',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = {'image_filename_train': image_filename_train, 'mask': mask_files})\n",
    "df_training, df_testing = train_test_split(df, test_size = 0.05)\n",
    "df_training, df_val = train_test_split(df_training, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(\n",
    "    data_frame,\n",
    "    batch_size,\n",
    "    augmentation_dict,\n",
    "    image_color_mode=\"rgb\",\n",
    "    mask_color_mode=\"grayscale\",\n",
    "    image_save_prefix=\"image\",\n",
    "    mask_save_prefix=\"mask\",\n",
    "    save_to_dir=None,\n",
    "    target_size=(256, 256),\n",
    "    seed=1,\n",
    "):\n",
    "    image_datagen = ImageDataGenerator(**augmentation_dict)\n",
    "    mask_datagen = ImageDataGenerator(**augmentation_dict)\n",
    "    image_generator = image_datagen.flow_from_dataframe(\n",
    "        data_frame, x_col=\"image_filename_train\", class_mode=None, color_mode=image_color_mode, target_size=target_size, batch_size=batch_size, save_to_dir=save_to_dir, save_prefix=image_save_prefix, seed=seed,\n",
    "    )\n",
    "    mask_generator = mask_datagen.flow_from_dataframe(\n",
    "        data_frame, x_col=\"mask\", class_mode=None, color_mode=mask_color_mode, target_size=target_size, batch_size=batch_size, save_to_dir=save_to_dir, save_prefix=mask_save_prefix, seed=seed,\n",
    "    )\n",
    "    train_gen = zip(image_generator, mask_generator)\n",
    "    for (img, mask) in train_gen:\n",
    "        img, mask = norm_diagnose(img, mask)\n",
    "        yield (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size=(image_wdth, image_hght, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(inputs)\n",
    "    bn1 = Activation(\"relu\")(conv1)\n",
    "    conv1 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn1)\n",
    "    bn1 = BatchNormalization(axis=3)(conv1)\n",
    "    bn1 = Activation(\"relu\")(bn1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
    "    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(pool1)\n",
    "    bn2 = Activation(\"relu\")(conv2)\n",
    "    conv2 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn2)\n",
    "    bn2 = BatchNormalization(axis=3)(conv2)\n",
    "    bn2 = Activation(\"relu\")(bn2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
    "    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(pool2)\n",
    "    bn3 = Activation(\"relu\")(conv3)\n",
    "    conv3 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn3)\n",
    "    bn3 = BatchNormalization(axis=3)(conv3)\n",
    "    bn3 = Activation(\"relu\")(bn3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n",
    "    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(pool3)\n",
    "    bn4 = Activation(\"relu\")(conv4)\n",
    "    conv4 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn4)\n",
    "    bn4 = BatchNormalization(axis=3)(conv4)\n",
    "    bn4 = Activation(\"relu\")(bn4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n",
    "    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(pool4)\n",
    "    bn5 = Activation(\"relu\")(conv5)\n",
    "    conv5 = Conv2D(filters=1024, kernel_size=(3, 3), padding=\"same\")(bn5)\n",
    "    bn5 = BatchNormalization(axis=3)(conv5)\n",
    "    bn5 = Activation(\"relu\")(bn5)\n",
    "    up6 = concatenate([Conv2DTranspose(512, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn5), conv4], axis=3)\n",
    "    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(up6)\n",
    "    bn6 = Activation(\"relu\")(conv6)\n",
    "    conv6 = Conv2D(filters=512, kernel_size=(3, 3), padding=\"same\")(bn6)\n",
    "    bn6 = BatchNormalization(axis=3)(conv6)\n",
    "    bn6 = Activation(\"relu\")(bn6)\n",
    "    up7 = concatenate([Conv2DTranspose(256, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn6),conv3], axis=3)\n",
    "    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(up7)\n",
    "    bn7 = Activation(\"relu\")(conv7)\n",
    "    conv7 = Conv2D(filters=256, kernel_size=(3, 3), padding=\"same\")(bn7)\n",
    "    bn7 = BatchNormalization(axis=3)(conv7)\n",
    "    bn7 = Activation(\"relu\")(bn7)\n",
    "    up8 = concatenate([Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn7),conv2], axis=3)\n",
    "    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(up8)\n",
    "    bn8 = Activation(\"relu\")(conv8)\n",
    "    conv8 = Conv2D(filters=128, kernel_size=(3, 3), padding=\"same\")(bn8)\n",
    "    bn8 = BatchNormalization(axis=3)(conv8)\n",
    "    bn8 = Activation(\"relu\")(bn8)\n",
    "    up9 = concatenate([Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding=\"same\")(bn8),conv1],axis=3)\n",
    "    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(up9)\n",
    "    bn9 = Activation(\"relu\")(conv9)\n",
    "    conv9 = Conv2D(filters=64, kernel_size=(3, 3), padding=\"same\")(bn9)\n",
    "    bn9 = BatchNormalization(axis=3)(conv9)\n",
    "    bn9 = Activation(\"relu\")(bn9)\n",
    "    conv10 = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(bn9)\n",
    "    return Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hriday ahuja\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3545 validated image filenames.\n",
      "Found 3545 validated image filenames.\n",
      "Epoch 1/4\n",
      " 13/110 [==>...........................] - ETA: 3:30:53 - loss: -0.0517 - binary_accuracy: 0.6791 - intersection_over_union: 0.0267 - dice_coeffs: 0.0517"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "learning_rate = 1e-4\n",
    "EPOCHS = 4\n",
    "test_gener = train_generator(df_val, BATCH_SIZE,\n",
    "                                dict(), target_size=(image_hght, image_wdth))\n",
    "train_generator_args = dict(rotation_range=0.2, width_shift_range=0.05, height_shift_range=0.05, shear_range=0.05, zoom_range=0.05, horizontal_flip=True, fill_mode='nearest')\n",
    "train_gen = train_generator(df_training, BATCH_SIZE, train_generator_args, target_size=(image_hght, image_wdth))\n",
    "model = unet(input_size=(image_hght, image_wdth, 3))\n",
    "opt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss=dice_coeffloss, metrics=[\"binary_accuracy\", intersection_over_union, dice_coeffs])\n",
    "callbacks = [ModelCheckpoint('unet_brain_mri_seg.hdf5', verbose=1, save_best_only=True)]\n",
    "history = model.fit(train_gen, steps_per_epoch=len(df_training) / BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, validation_data = test_gener, validation_steps=len(df_val) / BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
